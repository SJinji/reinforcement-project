{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4CmyLRZJ+aIUo3cNHrC75",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SJinji/reinforcement_project/blob/environment/RL_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Frozen Lake with Reinforcement Learning**\n",
        "# BY Mengyu LIANG, Nhat Mai NGUYEN, Jinji SHEN"
      ],
      "metadata": {
        "id": "KuK34PFxOQ4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building Environment**"
      ],
      "metadata": {
        "id": "84nkyH6IOmAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "import enum"
      ],
      "metadata": {
        "id": "BTB3sFO9PL60"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the possible actions as an enumeration\n",
        "class Action(enum.Enum):\n",
        "    Left = 0\n",
        "    Right = 1\n",
        "    Up = 2\n",
        "    Down = 3\n",
        "\n",
        "# define the environment class\n",
        "class Environment:\n",
        "    def __init__(self):\n",
        "        # initialize the map, which is a 4x4 grid of characters\n",
        "        self.map = np.array([['S', 'F', 'F', 'F'], \n",
        "                             ['F', 'H', 'F', 'H'], \n",
        "                             ['F', 'F', 'F', 'H'], \n",
        "                             ['H', 'F', 'F', 'G']])\n",
        "        # define the action space as an array of possible actions\n",
        "        self.action_space = np.array([Action.Left, Action.Right, Action.Up, Action.Down])\n",
        "        # define the state space as an array of integers from 0 to 15\n",
        "        self.state_space = [i for i in range(np.array(self.map).size)]\n",
        "\n",
        "        # define the states where certain actions are invalid (i.e. the agent would go off the map)\n",
        "        self.no_left_states = [4, 8, 0, 12]\n",
        "        self.no_right_states = [7, 11, 3, 15]\n",
        "        self.no_up_states = [1, 2, 0, 3]\n",
        "        self.no_down_states = [13, 14, 12, 15]\n",
        "\n",
        "        # initialize the current state to be the top-left corner of the map\n",
        "        self.current_state = 0\n",
        "\n",
        "    # return the action space\n",
        "    def get_action_space(self):\n",
        "        return self.action_space\n",
        "\n",
        "    # return the state space\n",
        "    def get_state_space(self):\n",
        "        return self.state_space\n",
        "\n",
        "    # select a random action from the action space\n",
        "    def get_random_action(self):\n",
        "        return np.random.choice(self.action_space)\n",
        "\n",
        "    # take a step in the environment, given an action index\n",
        "    def step(self, action_index):\n",
        "        # convert the action index to an Action enumeration\n",
        "        action = Action(action_index)\n",
        "\n",
        "        # check if the action is invalid (i.e. would make the agent go off the map)\n",
        "        if self.invalid_action(action):\n",
        "            # if so, return the current state, reward of 0, and False to indicate that the episode is not over\n",
        "            return self.current_state, 0, False\n",
        "\n",
        "        # update the current state based on the action\n",
        "        if action == Action.Left:\n",
        "            self.current_state -= 1\n",
        "        elif action == Action.Right:\n",
        "            self.current_state += 1\n",
        "        elif action == Action.Up:\n",
        "            self.current_state -= 4\n",
        "        else:\n",
        "            self.current_state += 4\n",
        "\n",
        "        # get the row and column indices of the current state\n",
        "        row, column = self.get_indices_of_current_state()\n",
        "        # get the character at the current state's position on the map\n",
        "        letter = self.map[row][column]\n",
        "\n",
        "        # if the current state is a 'S' or 'F', return the current state, reward of 0, and False to indicate that the episode is not over\n",
        "        if letter == 'S' or letter == 'F':\n",
        "            return self.current_state, 0, False\n",
        "        # if the current state is a 'G', return the current state, reward of 1, and True to indicate that the episode is over\n",
        "        elif letter == 'G':\n",
        "            return self.current_state, 1, True\n",
        "        # if the current state is a 'H', return the current state, reward of 0, and True to indicate that the episode is over\n",
        "            return self.current_state, 0, True\n",
        "\n",
        "    def invalid_action(self, action):\n",
        "        # Check if the chosen action is not allowed in the current state\n",
        "        if (action == Action.Left and self.current_state in self.no_left_states) or \\\n",
        "           (action == Action.Right and self.current_state in self.no_right_states) or \\\n",
        "           (action == Action.Up and self.current_state in self.no_up_states) or \\\n",
        "           (action == Action.Down and self.current_state in self.no_down_states):\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def get_indices_of_current_state(self):\n",
        "        # Convert the current state to a row and column index on the map\n",
        "        temp = 0\n",
        "        for i in range(len(self.map)):\n",
        "            for j in range(len(self.map[0])):\n",
        "                if temp == self.current_state:\n",
        "                    return i, j\n",
        "                temp += 1\n",
        "\n",
        "    def reset(self):\n",
        "        # reset the current state to the starting state (which is 0 in this case) and returns the new current state\n",
        "        self.current_state = 0\n",
        "        return self.current_state\n",
        "\n",
        "    def print_current_state(self):\n",
        "        # make a copy of the map\n",
        "        temp_map = deepcopy(self.map)\n",
        "        row, column = self.get_indices_of_current_state()\n",
        "        # replace the cell at the current state with an 'X' symbol in the copy\n",
        "        temp_map[row][column] = 'X'\n",
        "\n",
        "        # prints the map with the current state symbol to the console.\n",
        "        for r in temp_map:\n",
        "            print(r[0], r[1], r[2], r[3])\n",
        "        print()"
      ],
      "metadata": {
        "id": "mGhSo5K4R_Ee"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}